---
title: "comprehensive_model_markdown"
output: html_notebook
---

This markdown document is used to explain the model specifications that will be called in the run_models script (aka this is the model itself). Make any edits to the comprehensive_model.txt document, not this one- this one does not feed into the run_models script.

Model structure allows for the estimation of the effects of various predictors on the growth index while accounting for year-to-year variability. The use of uninformative priors allows the data to drive the parameter estimates.

## full code
```{r}
model {
  for (i in 1:N) {
    y[i] ~ dnorm(mu[i], tau)
    mu[i] <- beta[1] + beta[2] * nest_density[i] + beta[3] * road_proximity[i] + 
             beta[4] * bcnh_nest_success[i] + beta[5] * dcco_usurpation[i] + 
             beta[6] * dcco_management[i] + alpha_year[year[i]]
    
    # Log-likelihood for WAIC calculation
    loglik[i] <- logdensity.norm(y[i], mu[i], tau)
    
    # Generate posterior predictive samples
    y_rep[i] ~ dnorm(mu[i], tau)
  }
  
  # Priors for fixed effects
  for (j in 1:6) {
    beta[j] ~ dnorm(0, 0.001)
  }
  
  # Prior for residual precision
  tau <- pow(sigma, -2)
  sigma ~ dunif(0, 100)
  
  # Priors for random year effect
  for (t in 1:N_years) {
    alpha_year[t] ~ dnorm(0, tau_year)
  }
  tau_year <- pow(sigma_year, -2)
  sigma_year ~ dunif(0, 100)
}
```

## Breakdown starts here: 
# 1. main loop for each observation
```{r}
for (i in 1:N) {
  y[i] ~ dnorm(mu[i], tau)
```
creates loop for each observation (i) from 1 to N (N= total number of observations)
y(i)= the growth index. Modeled as coming from normal distribution with mean- mu[i] - and precision- tau.

# 2. linear predictor
```{r}
mu[i] <- beta[1] + beta[2] * nest_density[i] + beta[3] * road_proximity[i] + 
         beta[4] * bcnh_nest_success[i] + beta[5] * dcco_usurpation[i] + 
         beta[6] * dcco_management[i] + alpha_year[year[i]]
```
Defines mean of normal distribution for each observation. beta[1]= intercept. beta[2] to beta[6] are coefficients for fixed effects. alpha_year[year[i]] is random effect of year of observation i.

intercept = part of regression analysis. Baseline value of response variable (growth index) when all other predictors are zero. Ensures regression line is not forced to go through origin (0,0). Provides 'starting point' from which effects of other variables are measured.

# 3. log-likelihood calculation
```{r}
loglik[i] <- logdensity.norm(y[i], mu[i], tau)
```
calculates log-likelihood for each observation. used for computing WAIC (widely applicable information criterion) for model comparison.

log-likelihood = measures how probable the observed data is for different values of the statistical model's parameters. In Bayesian statistics, combined with the prior to form the posterior distribution. Key component of model comparison.For a normal distribution (as in this model):
log-likelihood = -0.5 * (log(2π) + log(σ²) + (y - μ)² / σ²)
Where μ is the mean (mu[i] in the model) and σ² is the variance (1/tau in the model)

# 4. posterior predictive sampling
```{r}
y_rep[i] ~ dnorm(mu[i], tau)
```
generates new data points, also called "replicated" value (y_rep) for observation [i] based on current parameter estimates. used for model checking and validation- if y_rep doesn't look similar to y, may not be capturing important aspects of the data.
uses the same mean (mu[i]) and precision (tau) as the model for the observed data.

# 5. priors for fixed effects
```{r}
for (j in 1:6) {
  beta[j] ~ dnorm(0, 0.001)
}
```
sets prior distributions for beta coefficients. 
uses normal distribution with mean 0 and precision 0.001 (equivalent to standard deviation of about 31.6)
this is a relatively uninformative prior.

# 6. prior for residual variance
```{r}
tau <- pow(sigma, -2)
sigma ~ dunif(0, 100)
```
sigma (standard deviation) is given a uniform prior between 0 and 100.
tau (precision) is calculated as 1 / sigma^2.

residual variance = variability in the dependent variable (y) that remains unexplained by independent variables (x) in the model. calculated as differences between observed values and values predicted by the model. residual variance is the average of the squared residuals.
represented by sigma in the model and the inverse is precision.

interpretation: smaller rv indicates that model explains more of the variation in the data. model with low rv relative to total variance in y is generally considered to be performing well.
larger rv suggests might be important factors not included in the model or that relationship is noisy.

# 7. priors for random year effect:
```{r}
for (t in 1:N_years) {
  alpha_year[t] ~ dnorm(0, tau_year)
}
tau_year <- pow(sigma_year, -2)
sigma_year ~ dunif(0, 100)
```
Each year's random effect (alpha_year[t]) is modeled as coming from a normal distribution with mean 0 and precision tau_year.

tau_year <- pow(sigma_year, -2) converts standard deviation sigma_year to precision tau_year
in JAGS, normal distributions are parameterized by precision instead of variance.
sigma_year (standard deviation of the year effect) is given a uniform prior between 0 and 100.
tau_year (precision of the year effect) is calculated as 1 / sigma_year^2.

sigma_year ~ dunif(0, 100) sets uniform prior on sigma_year between 0 and 100, a relatively uninformative prior, allowing data to largely dtermine magnitude of year-to-year variability.

Creates a hierarchical model where individual year effects are pooled towards common mean (0).
Estimates of alpha_year for years with little data will be shrunk towards 0 and can help reduce overfitting.
assumes year effects are exchangeable, ie no temporal trend. If suspect a temporal trend may need to modify the model.
The uniform prior on sigma_year allows the model to adapt to different scales of year-to-year variability. If the data suggest little year effect, sigma_year will be small; if year effects are substantial, sigma_year can become large.

Can assess the importance of the year effect by comparing this model to one without the random year effect, using criteria like WAIC or leave-one-out cross-validation.

Allows model to account for year-to-year variability in the cormorant colony growth index, while still pooling information across years. It's particularly useful when if expect years to differ but don't have specific hypotheses about how or why they differ.
